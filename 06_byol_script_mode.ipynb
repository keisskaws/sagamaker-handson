{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOL (Bring Your Own Library) Script Mode\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ç‹¬è‡ªã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸSageMakerã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’ä½“é¨“ã—ã¾ã™ã€‚\n",
    "\n",
    "## ğŸ¯ å­¦ç¿’ç›®æ¨™\n",
    "- ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½œæˆã¨ä½¿ç”¨\n",
    "- Dockerã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ã£ãŸBYOL\n",
    "- ç‹¬è‡ªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…ã¨å®Ÿè¡Œ\n",
    "\n",
    "## â±ï¸ å®Ÿè¡Œæ™‚é–“ç›®å®‰\n",
    "- **ç’°å¢ƒæº–å‚™**: 5-10åˆ†\n",
    "- **ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½œæˆ**: 5åˆ†\n",
    "- **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ**: 10-15åˆ†\n",
    "- **åˆè¨ˆ**: ç´„25-35åˆ†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# SageMakerè¨­å®š\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "print(f\"SageMaker role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"S3 bucket: {bucket}\")\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(\"\\nğŸ“ BYOL Script Modeè¬›ç¾©ã‚’é–‹å§‹ã—ã¾ã™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BYOLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª\n",
    "byol_dir = './byol_docker'\n",
    "if os.path.exists(byol_dir):\n",
    "    print(f\"âœ… BYOLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã™: {byol_dir}\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º\n",
    "    print(\"\\nBYOLãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ:\")\n",
    "    for root, dirs, files in os.walk(byol_dir):\n",
    "        level = root.replace(byol_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f\"{subindent}{file}\")\nelse:\n",
    "    print(f\"âŒ BYOLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {byol_dir}\")\n",
    "    print(\"\\nğŸ’¡ è§£æ±ºæ–¹æ³•:\")\n",
    "    print(\"1. å‰ã®ã‚»ãƒ«ã§BYOLãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãä½œæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\")\n",
    "    print(\"2. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ãŒæ­£ã—ã„ã‹ç¢ºèª\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ†ã‚¹ãƒˆ\n",
    "import sys\n",
    "sys.path.append('./byol_docker/custom_ml_lib')\n",
    "\n",
    "try:\n",
    "    from custom_ml_lib.custom_classifier import CustomEnsembleClassifier\n",
    "    print(\"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ\")\n",
    "    \n",
    "    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèªï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿®æ­£ï¼‰\n",
    "    from sklearn.datasets import make_classification\n",
    "    X_test, y_test = make_classification(\n",
    "        n_samples=200,           # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—åŠ \n",
    "        n_features=10,           # ç‰¹å¾´é‡æ•°\n",
    "        n_informative=8,         # æƒ…å ±ã®ã‚ã‚‹ç‰¹å¾´é‡æ•°ã‚’å¢—åŠ ï¼ˆé‡è¦ï¼ï¼‰\n",
    "        n_redundant=2,           # å†—é•·ãªç‰¹å¾´é‡æ•°\n",
    "        n_classes=3,             # ã‚¯ãƒ©ã‚¹æ•°\n",
    "        n_clusters_per_class=1,  # ã‚¯ãƒ©ã‚¹ã‚ãŸã‚Šã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ã‚’1ã«\n",
    "        random_state=42,\n",
    "        class_sep=1.0            # ã‚¯ãƒ©ã‚¹é–“ã®åˆ†é›¢åº¦ã‚’è¿½åŠ \n",
    "    )\n",
    "    \n",
    "    print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {X_test.shape}, ã‚¯ãƒ©ã‚¹æ•°: {len(set(y_test))}\")\n",
    "    \n",
    "    # ã‚«ã‚¹ã‚¿ãƒ åˆ†é¡å™¨ã®ãƒ†ã‚¹ãƒˆ\n",
    "    classifier = CustomEnsembleClassifier(\n",
    "        use_rf=True,\n",
    "        use_gb=True,\n",
    "        use_lr=True\n",
    "    )\n",
    "    \n",
    "    classifier.fit(X_test, y_test)\n",
    "    predictions = classifier.predict(X_test[:10])\n",
    "    probabilities = classifier.predict_proba(X_test[:10])\n",
    "    \n",
    "    print(f\"äºˆæ¸¬çµæœ: {predictions}\")\n",
    "    print(f\"äºˆæ¸¬ç¢ºç‡å½¢çŠ¶: {probabilities.shape}\")\n",
    "    print(\"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å‹•ä½œç¢ºèªå®Œäº†\")\n",
    "    \nexcept ImportError as e:\n",
    "    print(f\"âŒ ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}\")\nexcept Exception as e:\n",
    "    print(f\"âŒ ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ†ã‚¹ãƒˆã«å¤±æ•—: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ãƒ‡ãƒ¼ã‚¿æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹æ¤œå‡º\n",
    "def find_data_path():\n",
    "    possible_paths = [\n",
    "        './data/',\n",
    "        '../data/',\n",
    "        '~/sagemaker-lecture-version/data/',\n",
    "        os.path.expanduser('~/sagemaker-lecture-version/data/')\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        expanded_path = os.path.expanduser(path)\n",
    "        train_file = os.path.join(expanded_path, 'train_lecture.csv')\n",
    "        if os.path.exists(train_file):\n",
    "            return expanded_path\n",
    "    return None\n",
    "\n",
    "data_path = find_data_path()\n",
    "\n",
    "if data_path:\n",
    "    print(f\"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {data_path}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    train_s3_path = sagemaker_session.upload_data(\n",
    "        os.path.join(data_path, 'train_lecture.csv'),\n",
    "        bucket=bucket,\n",
    "        key_prefix='byol-lecture/train'\n",
    "    )\n",
    "    \n",
    "    test_s3_path = sagemaker_session.upload_data(\n",
    "        os.path.join(data_path, 'test_lecture.csv'),\n",
    "        bucket=bucket,\n",
    "        key_prefix='byol-lecture/test'\n",
    "    )\n",
    "    \n",
    "    validation_s3_path = sagemaker_session.upload_data(\n",
    "        os.path.join(data_path, 'validation_lecture.csv'),\n",
    "        bucket=bucket,\n",
    "        key_prefix='byol-lecture/validation'\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†:\")\n",
    "    print(f\"  Train: {train_s3_path}\")\n",
    "    print(f\"  Test: {test_s3_path}\")\n",
    "    print(f\"  Validation: {validation_s3_path}\")\nelse:\n",
    "    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®æ§‹ç¯‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸æ§‹ç¯‰ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "build_docker = False  # Trueã«å¤‰æ›´ã—ã¦Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ§‹ç¯‰\n",
    "\n",
    "if build_docker and os.path.exists('./byol_docker/Dockerfile'):\n",
    "    print(\"Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ§‹ç¯‰ä¸­...ï¼ˆæ•°åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰\")\n",
    "    \n",
    "    # ECRãƒªãƒã‚¸ãƒˆãƒªå\n",
    "    repository_name = 'sagemaker-byol-lecture'\n",
    "    image_tag = 'latest'\n",
    "    \n",
    "    # ECRã®ãƒ•ãƒ«URI\n",
    "    ecr_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repository_name}:{image_tag}\"\n",
    "    \n",
    "    try:\n",
    "        # Dockerã‚¤ãƒ¡ãƒ¼ã‚¸æ§‹ç¯‰\n",
    "        build_cmd = f\"cd ./byol_docker && docker build -t {repository_name}:{image_tag} .\"\n",
    "        result = subprocess.run(build_cmd, shell=True, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… Dockerã‚¤ãƒ¡ãƒ¼ã‚¸æ§‹ç¯‰å®Œäº†\")\n",
    "            print(f\"ã‚¤ãƒ¡ãƒ¼ã‚¸å: {repository_name}:{image_tag}\")\n",
    "            \n",
    "            # ECRã«ãƒ—ãƒƒã‚·ãƒ¥ï¼ˆå®Ÿéš›ã®ç’°å¢ƒã§ã¯å¿…è¦ï¼‰\n",
    "            print(f\"\\nğŸ’¡ ECRã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹å ´åˆ:\")\n",
    "            print(f\"1. aws ecr create-repository --repository-name {repository_name}\")\n",
    "            print(f\"2. docker tag {repository_name}:{image_tag} {ecr_uri}\")\n",
    "            print(f\"3. docker push {ecr_uri}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Dockerã‚¤ãƒ¡ãƒ¼ã‚¸æ§‹ç¯‰ã«å¤±æ•—: {result.stderr}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Dockeræ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}\")\nelse:\n",
    "    print(\"â­ï¸ Dockerã‚¤ãƒ¡ãƒ¼ã‚¸æ§‹ç¯‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆbuild_docker=Falseï¼‰\")\n",
    "    print(\"\\nğŸ’¡ å®Ÿéš›ã®ç’°å¢ƒã§ã¯:\")\n",
    "    print(\"1. Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ§‹ç¯‰\")\n",
    "    print(\"2. ECRã«ãƒ—ãƒƒã‚·ãƒ¥\")\n",
    "    print(\"3. ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SageMaker Script Modeï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Script Modeã§ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨\n",
    "# æ³¨æ„: ã“ã®ä¾‹ã§ã¯ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’source_dirã«å«ã‚ã‚‹æ–¹æ³•ã‚’ä½¿ç”¨\n",
    "\n",
    "if 'train_s3_path' in locals():\n",
    "    from sagemaker.sklearn.estimator import SKLearn\n",
    "    \n",
    "    # SKLearnã‚¨ã‚¹ãƒ†ã‚£ãƒ¡ãƒ¼ã‚¿ãƒ¼ï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä»˜ãï¼‰\n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point='train.py',\n",
    "        source_dir='./byol_docker',  # ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "        role=role,\n",
    "        instance_type='ml.m5.large',\n",
    "        instance_count=1,\n",
    "        framework_version='1.0-1',\n",
    "        py_version='py3',\n",
    "        hyperparameters={\n",
    "            'use-custom-ensemble': 'true',\n",
    "            'ensemble-rf': 'true',\n",
    "            'ensemble-gb': 'true',\n",
    "            'ensemble-lr': 'true',\n",
    "            'feature-selection-k': 20\n",
    "        },\n",
    "        output_path=f's3://{bucket}/byol-lecture/output'\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… BYOL SKLearnã‚¨ã‚¹ãƒ†ã‚£ãƒ¡ãƒ¼ã‚¿ãƒ¼ä½œæˆå®Œäº†\")\n",
    "    print(f\"ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ: train.py\")\n",
    "    print(f\"ã‚½ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ./byol_docker\")\n",
    "    print(f\"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {sklearn_estimator.hyperparameters()}\")\nelse:\n",
    "    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚¨ã‚¹ãƒ†ã‚£ãƒ¡ãƒ¼ã‚¿ãƒ¼ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BYOLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "if 'sklearn_estimator' in locals():\n",
    "    print(\"BYOL Script Modeãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...\")\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "        sklearn_estimator.fit({\n",
    "            'train': train_s3_path,\n",
    "            'test': test_s3_path,\n",
    "            'validation': validation_s3_path\n",
    "        }, wait=True)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… BYOLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†: {training_time:.2f}ç§’\")\n",
    "        print(f\"ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›: {sklearn_estimator.model_data}\")\n",
    "        \n",
    "        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–åã‚’ä¿å­˜\n",
    "        training_job_name = sklearn_estimator.latest_training_job.name\n",
    "        print(f\"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–å: {training_job_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ BYOLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        print(\"\\nğŸ’¡ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:\")\n",
    "        print(\"1. ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãŒãªã„ã‹ç¢ºèª\")\n",
    "        print(\"2. train.pyã®ãƒ‘ã‚¹ãŒæ­£ã—ã„ã‹ç¢ºèª\")\n",
    "        print(\"3. ä¾å­˜é–¢ä¿‚ãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\")\nelse:\n",
    "    print(\"âŒ ã‚¨ã‚¹ãƒ†ã‚£ãƒ¡ãƒ¼ã‚¿ãƒ¼ãŒä½œæˆã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. çµæœã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®ç¢ºèª\n",
    "if 'training_job_name' in locals():\n",
    "    print(\"=== BYOL Script Mode å®Ÿè¡Œçµæœ ===\")\n",
    "    \n",
    "    # CloudWatchãƒ­ã‚°ã®ç¢ºèªï¼ˆæœ€å¾Œã®æ•°è¡Œï¼‰\n",
    "    try:\n",
    "        logs_client = boto3.client('logs', region_name=region)\n",
    "        log_group = f'/aws/sagemaker/TrainingJobs'\n",
    "        log_stream = training_job_name\n",
    "        \n",
    "        response = logs_client.get_log_events(\n",
    "            logGroupName=log_group,\n",
    "            logStreamName=log_stream,\n",
    "            startFromHead=False,\n",
    "            limit=20\n",
    "        )\n",
    "        \n",
    "        print(\"\\nğŸ“‹ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚°ï¼ˆæœ€å¾Œã®20è¡Œï¼‰:\")\n",
    "        for event in response['events']:\n",
    "            print(event['message'].strip())\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ãƒ­ã‚°ã®å–å¾—ã«å¤±æ•—: {e}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š å®Ÿè¡Œã‚µãƒãƒªãƒ¼:\")\n",
    "    print(f\"  ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–: {training_job_name}\")\n",
    "    print(f\"  å®Ÿè¡Œæ™‚é–“: {training_time:.2f}ç§’\")\n",
    "    print(f\"  ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›: {sklearn_estimator.model_data}\")\n",
    "    print(f\"  ä½¿ç”¨ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡å™¨\")\nelse:\n",
    "    print(\"âŒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¦ã„ãªã„ãŸã‚ã€çµæœç¢ºèªã‚’ã‚¹ã‚­ãƒƒãƒ—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ã¾ã¨ã‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== BYOL Script Mode è¬›ç¾©å®Œäº† ===\")\n",
    "print(\"\\nğŸ“ å­¦ç¿’å†…å®¹:\")\n",
    "print(\"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½œæˆæ–¹æ³•\")\n",
    "print(\"âœ… ç‹¬è‡ªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…\")\n",
    "print(\"âœ… SageMaker Script Modeã§ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨\")\n",
    "print(\"âœ… BYOLï¼ˆBring Your Own Libraryï¼‰ã®æ¦‚å¿µ\")\n",
    "print(\"\\nğŸš€ BYOLã®åˆ©ç‚¹:\")\n",
    "print(\"ğŸ“¦ ç‹¬è‡ªã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨å¯èƒ½\")\n",
    "print(\"ğŸ”§ æ—¢å­˜ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ´»ç”¨\")\n",
    "print(\"âš¡ ç‰¹å®šã®å•é¡Œã«æœ€é©åŒ–ã•ã‚ŒãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\")\n",
    "print(\"ğŸ”„ æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å†åˆ©ç”¨\")\n",
    "print(\"\\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "print(\"1. ã‚ˆã‚Šè¤‡é›‘ãªã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…\")\n",
    "print(\"2. Dockerã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ã£ãŸå®Œå…¨ãªBYOL\")\n",
    "print(\"3. ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–\")\n",
    "print(\"4. æœ¬ç•ªç’°å¢ƒã§ã®ãƒ‡ãƒ—ãƒ­ã‚¤\")\n",
    "print(\"\\nğŸ’¡ å®Ÿéš›ã®ä½¿ç”¨ä¾‹:\")\n",
    "print(\"- ä¼æ¥­ç‹¬è‡ªã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \")\n",
    "print(\"- ç ”ç©¶æ©Ÿé–¢ã®æœ€æ–°æ‰‹æ³•\")\n",
    "print(\"- ç‰¹å®šãƒ‰ãƒ¡ã‚¤ãƒ³ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«\")\n",
    "print(\"- ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
