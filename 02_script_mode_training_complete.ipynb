{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 💻 Step 2: Script Mode での機械学習\n",
    "\n",
    "前のノートブックで作成・管理したS3データを使って、**Script Mode**での機械学習を実行します。\n",
    "\n",
    "## 🎯 このノートブックで学ぶこと\n",
    "- S3データの読み込みと活用\n",
    "- ノートブック内での機械学習パイプライン\n",
    "- 複数モデルの比較と評価\n",
    "- Script Modeの特徴と利点\n",
    "\n",
    "## ⏱️ 実行時間: 約5-8分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定とS3データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"💻 Script Mode環境の設定\")\n",
    "print(f\"📅 開始時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 前のノートブックで保存したS3パス情報を読み込み\n",
    "try:\n",
    "    with open('s3_data_paths.json', 'r') as f:\n",
    "        s3_paths = json.load(f)\n",
    "    print(\"✅ S3データパス情報を読み込み完了\")\n",
    "    for data_type, path in s3_paths.items():\n",
    "        print(f\"  📊 {data_type}: {path}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ S3パス情報が見つかりません\")\n",
    "    print(\"🔄 先に 01_data_management.ipynb を実行してください\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. S3からのデータ読み込み\n",
    "\n",
    "### 📚 学習ポイント\n",
    "- S3から直接DataFrameに読み込み\n",
    "- データの基本確認\n",
    "- 読み込み時間の測定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📥 S3からデータを読み込み中...\")\n",
    "data_load_start = time.time()\n",
    "\n",
    "# S3から各データセットを読み込み\n",
    "datasets = {}\n",
    "for data_type, s3_path in s3_paths.items():\n",
    "    print(f\"  📊 {data_type} データを読み込み中...\")\n",
    "    \n",
    "    file_start = time.time()\n",
    "    datasets[data_type] = pd.read_csv(s3_path)\n",
    "    file_time = time.time() - file_start\n",
    "    \n",
    "    print(f\"    ✅ 完了 ({file_time:.2f}秒, 形状: {datasets[data_type].shape})\")\n",
    "\n",
    "data_load_time = time.time() - data_load_start\n",
    "\n",
    "print(f\"\\n📊 データ読み込み完了:\")\n",
    "print(f\"  ⏱️ 総読み込み時間: {data_load_time:.2f}秒\")\n",
    "print(f\"  📈 訓練データ: {datasets['train'].shape}\")\n",
    "print(f\"  📉 検証データ: {datasets['validation'].shape}\")\n",
    "print(f\"  🎯 テストデータ: {datasets['test'].shape}\")\n",
    "\n",
    "# データの基本確認\n",
    "train_data = datasets['train']\n",
    "val_data = datasets['validation']\n",
    "test_data = datasets['test']\n",
    "\n",
    "print(f\"\\n🔍 データ品質確認:\")\n",
    "print(f\"  📊 クラス分布（訓練）: {dict(train_data['target'].value_counts().sort_index())}\")\n",
    "print(f\"  🔍 欠損値（訓練）: {train_data.isnull().sum().sum()}個\")\n",
    "print(f\"  📏 特徴量数: {len([col for col in train_data.columns if col != 'target'])}個\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. データの可視化と理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの可視化\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# クラス分布\n",
    "plt.subplot(1, 3, 1)\n",
    "train_data['target'].value_counts().plot(kind='bar', color=['skyblue', 'lightgreen', 'salmon'])\n",
    "plt.title('クラス分布（不均衡データ）')\n",
    "plt.xlabel('クラス')\n",
    "plt.ylabel('サンプル数')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 重要特徴量の分布\n",
    "plt.subplot(1, 3, 2)\n",
    "for target in train_data['target'].unique():\n",
    "    subset = train_data[train_data['target'] == target]\n",
    "    plt.hist(subset['feature_00'].dropna(), alpha=0.7, label=f'Class {target}', bins=20)\n",
    "plt.title('重要特徴量の分布')\n",
    "plt.xlabel('feature_00')\n",
    "plt.ylabel('頻度')\n",
    "plt.legend()\n",
    "\n",
    "# 欠損値パターン\n",
    "plt.subplot(1, 3, 3)\n",
    "missing_data = train_data.isnull().sum()\n",
    "missing_features = missing_data[missing_data > 0]\n",
    "if len(missing_features) > 0:\n",
    "    missing_features.plot(kind='bar')\n",
    "    plt.title('欠損値パターン')\n",
    "    plt.xlabel('特徴量')\n",
    "    plt.ylabel('欠損値数')\n",
    "    plt.xticks(rotation=45)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, '欠損値なし', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.title('欠損値パターン')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 データ理解完了: S3から読み込んだデータの特徴を確認しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Script Mode での機械学習実行\n",
    "\n",
    "### 📚 学習ポイント\n",
    "- 前処理パイプラインの構築\n",
    "- 複数モデルの比較\n",
    "- ハイパーパラメータ最適化\n",
    "- 結果の評価と可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lecture_preprocessing_pipeline():\n",
    "    \"\"\"講義用：軽量前処理パイプライン\"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),    # 欠損値補完\n",
    "        ('scaler', StandardScaler()),                     # 標準化\n",
    "        ('feature_selection', SelectKBest(f_classif, k=20))  # 特徴選択\n",
    "    ])\n",
    "\n",
    "def train_lecture_models(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"講義用：軽量モデル比較\"\"\"\n",
    "    print(\"=== 💻 Script Mode: 機械学習実行開始 ===\")\n",
    "    print(\"⏱️ 予想実行時間: 3-6分\")\n",
    "    \n",
    "    # パラメータ数を削減（講義用）\n",
    "    models = {\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestClassifier(random_state=42),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [10, 20]\n",
    "            }\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'model': GradientBoostingClassifier(random_state=42),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'learning_rate': [0.1, 0.2]\n",
    "            }\n",
    "        },\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(random_state=42, max_iter=500),\n",
    "            'params': {\n",
    "                'C': [0.1, 1.0]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    best_models = {}\n",
    "    \n",
    "    for name, config in models.items():\n",
    "        print(f\"\\n📊 {name} を最適化中...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 軽量グリッドサーチ\n",
    "        grid_search = GridSearchCV(\n",
    "            config['model'],\n",
    "            config['params'],\n",
    "            cv=3,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # 評価\n",
    "        best_model = grid_search.best_estimator_\n",
    "        train_score = best_model.score(X_train, y_train)\n",
    "        val_score = best_model.score(X_val, y_val)\n",
    "        \n",
    "        # 軽量クロスバリデーション\n",
    "        cv_scores = cross_val_score(best_model, X_train, y_train, cv=3)\n",
    "        \n",
    "        best_models[name] = best_model\n",
    "        results[name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'train_score': train_score,\n",
    "            'val_score': val_score,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'training_time': training_time\n",
    "        }\n",
    "        \n",
    "        print(f\"  ✅ 最適パラメータ: {grid_search.best_params_}\")\n",
    "        print(f\"  📈 検証精度: {val_score:.4f}\")\n",
    "        print(f\"  ⏱️ 訓練時間: {training_time:.1f}秒\")\n",
    "    \n",
    "    # 最適モデル選択\n",
    "    best_model_name = max(results.keys(), key=lambda k: results[k]['val_score'])\n",
    "    best_model = best_models[best_model_name]\n",
    "    \n",
    "    print(f\"\\n🏆 最適モデル: {best_model_name}\")\n",
    "    print(f\"🎯 検証精度: {results[best_model_name]['val_score']:.4f}\")\n",
    "    \n",
    "    return best_model, best_model_name, results\n",
    "\n",
    "# Script Mode実行\n",
    "print(\"🚀 Script Mode機械学習開始...\")\n",
    "script_start_time = time.time()\n",
    "\n",
    "# データ準備\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "X_val = val_data.drop('target', axis=1)\n",
    "y_val = val_data['target']\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "print(f\"📊 データ形状確認:\")\n",
    "print(f\"  📈 訓練: {X_train.shape}\")\n",
    "print(f\"  📉 検証: {X_val.shape}\")\n",
    "print(f\"  🎯 テスト: {X_test.shape}\")\n",
    "\n",
    "# 前処理\n",
    "print(f\"\\n🔧 前処理実行中...\")\n",
    "preprocessing_start = time.time()\n",
    "preprocessor = create_lecture_preprocessing_pipeline()\n",
    "X_train_processed = preprocessor.fit_transform(X_train, y_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "preprocessing_time = time.time() - preprocessing_start\n",
    "\n",
    "print(f\"✅ 前処理完了: {preprocessing_time:.1f}秒\")\n",
    "print(f\"📉 特徴量数: {X_train.shape[1]} → {X_train_processed.shape[1]}\")\n",
    "\n",
    "# モデル訓練・比較\n",
    "script_model, script_best_name, script_results = train_lecture_models(\n",
    "    X_train_processed, y_train, X_val_processed, y_val\n",
    ")\n",
    "\n",
    "script_total_time = time.time() - script_start_time\n",
    "print(f\"\\n🎉 Script Mode完了: {script_total_time:.1f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Script Mode結果の評価と可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script Modeモデルの評価\n",
    "print(\"=== 📊 Script Mode: 結果評価 ===\")\n",
    "\n",
    "script_predictions = script_model.predict(X_test_processed)\n",
    "script_accuracy = accuracy_score(y_test, script_predictions)\n",
    "\n",
    "print(f\"🎯 テスト精度: {script_accuracy:.4f}\")\n",
    "print(f\"\\n📋 分類レポート:\")\n",
    "print(classification_report(y_test, script_predictions))\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 混同行列\n",
    "plt.subplot(1, 3, 1)\n",
    "cm = confusion_matrix(y_test, script_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'混同行列 - {script_best_name}')\n",
    "plt.xlabel('予測')\n",
    "plt.ylabel('実際')\n",
    "\n",
    "# モデル比較（精度）\n",
    "plt.subplot(1, 3, 2)\n",
    "model_names = list(script_results.keys())\n",
    "val_scores = [script_results[name]['val_score'] for name in script_results]\n",
    "colors = ['skyblue', 'lightgreen', 'salmon']\n",
    "bars = plt.bar(model_names, val_scores, color=colors)\n",
    "plt.title('モデル別検証精度')\n",
    "plt.ylabel('精度')\n",
    "plt.ylim(0, 1)\n",
    "# 値をバーの上に表示\n",
    "for bar, score in zip(bars, val_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 訓練時間比較\n",
    "plt.subplot(1, 3, 3)\n",
    "training_times = [script_results[name]['training_time'] for name in script_results]\n",
    "bars = plt.bar(model_names, training_times, color=colors)\n",
    "plt.title('モデル別訓練時間')\n",
    "plt.ylabel('時間（秒）')\n",
    "# 値をバーの上に表示\n",
    "for bar, time_val in zip(bars, training_times):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "             f'{time_val:.1f}s', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n📈 Script Mode結果サマリー:\")\n",
    "print(f\"  🏆 最適モデル: {script_best_name}\")\n",
    "print(f\"  🎯 テスト精度: {script_accuracy:.4f}\")\n",
    "print(f\"  ⏱️ 総実行時間: {script_total_time:.1f}秒\")\n",
    "print(f\"  🔧 前処理時間: {preprocessing_time:.1f}秒\")\n",
    "print(f\"  🤖 モデル訓練時間: {sum(training_times):.1f}秒\")\n",
    "\n",
    "# Script Mode情報を保存（比較用）\n",
    "script_mode_info = {\n",
    "    'best_model': script_best_name,\n",
    "    'test_accuracy': script_accuracy,\n",
    "    'total_time': script_total_time,\n",
    "    'preprocessing_time': preprocessing_time,\n",
    "    'training_times': training_times,\n",
    "    'model_results': script_results\n",
    "}\n",
    "\n",
    "with open('script_mode_info.json', 'w') as f:\n",
    "    json.dump(script_mode_info, f, indent=2, default=str)\n",
    "    \n",
    "print(f\"\\n💾 Script Mode情報を保存: script_mode_info.json\")\n",
    "print(f\"🚀 次のノートブック: 03_training_jobs.ipynb\")\n",
    "print(f\"   同じS3データを使ってTraining Jobsを実行します！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}