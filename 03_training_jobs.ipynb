{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â˜ï¸ Step 3: Training Jobs ã§ã®æ©Ÿæ¢°å­¦ç¿’ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
    "\n",
    "å‰ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½œæˆã—ãŸS3ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€**SageMaker Training Jobs**ã§ã®æ©Ÿæ¢°å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "## ğŸ¯ ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å­¦ã¶ã“ã¨\n",
    "- S3ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸTraining Jobsã®å®Ÿè¡Œ\n",
    "- ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ©Ÿæ¢°å­¦ç¿’\n",
    "- Training Jobsã®ç›£è¦–ã¨çµæœå–å¾—\n",
    "- Script Mode vs Training Jobsã®é•ã„\n",
    "\n",
    "## â±ï¸ å®Ÿè¡Œæ™‚é–“: ç´„8-12åˆ†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šã¨S3ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# SageMakerè¨­å®š\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(\"â˜ï¸ Training Jobsç’°å¢ƒã®è¨­å®š\")\n",
    "print(f\"ğŸ“… é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ“ Region: {region}\")\n",
    "print(f\"ğŸ‘¤ Role: {role.split('/')[-1]}\")\n",
    "\n",
    "# S3ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æƒ…å ±ã‚’èª­ã¿è¾¼ã¿\n",
    "try:\n",
    "    with open('s3_data_paths.json', 'r') as f:\n",
    "        s3_paths = json.load(f)\n",
    "    print(\"\\nâœ… S3ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æƒ…å ±ã‚’èª­ã¿è¾¼ã¿å®Œäº†\")\n",
    "    for data_type, path in s3_paths.items():\n",
    "        print(f\"  ğŸ“Š {data_type}: {path}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ S3ãƒ‘ã‚¹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    print(\"ğŸ”„ å…ˆã« 01_data_management.ipynb ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
    "import os\n",
    "\n",
    "print(\"ğŸ” å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªä¸­...\")\n",
    "\n",
    "# scripts/train_lecture.pyã®å­˜åœ¨ç¢ºèª\n",
    "script_path = 'scripts/train_lecture.py'\n",
    "if os.path.exists(script_path):\n",
    "    print(f\"âœ… {script_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª\n",
    "    file_size = os.path.getsize(script_path)\n",
    "    print(f\"  ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes\")\n",
    "else:\n",
    "    print(f\"âŒ {script_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    print(\"\\nâš ï¸ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "    print(\"ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:\")\n",
    "    print(\"1. æ­£ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ã§ä½œæ¥­ã—ã¦ã„ã‚‹ã‹ç¢ºèª\")\n",
    "    print(\"2. GitHubã‹ã‚‰æ­£ã—ãã‚¯ãƒ­ãƒ¼ãƒ³ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\")\n",
    "    print(\"3. scripts/ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã€ãã®ä¸­ã«train_lecture.pyãŒã‚ã‚‹ã‹ç¢ºèª\")\n",
    "    \n",
    "    raise FileNotFoundError(f\"{script_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# scriptsãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹ã‚’è¡¨ç¤º\n",
    "print(\"\\nğŸ“ scriptsãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹:\")\n",
    "if os.path.exists('scripts'):\n",
    "    script_files = [f for f in os.listdir('scripts') if f.endswith('.py')]\n",
    "    for file in sorted(script_files):\n",
    "        file_path = os.path.join('scripts', file)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        print(f\"  ğŸ“„ {file} ({file_size:,} bytes)\")\n",
    "    \n",
    "    if not script_files:\n",
    "        print(\"  âŒ scriptsãƒ•ã‚©ãƒ«ãƒ€ã«.pyãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    print(\"  âŒ scriptsãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Jobsç”¨Estimatorã®è¨­å®š\n",
    "\n",
    "### ğŸ“š å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ\n",
    "- SKLearn Estimatorã®è¨­å®š\n",
    "- ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã®é¸æŠ\n",
    "- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ Training Jobsç”¨Estimatorã‚’è¨­å®šä¸­...\")\n",
    "\n",
    "# è¬›ç¾©ç”¨Training Jobsè¨­å®š\n",
    "lecture_estimator = SKLearn(\n",
    "    entry_point='scripts/train_lecture.py',  # scriptsãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š\n",
    "    framework_version='1.0-1',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.large',  # è¬›ç¾©ç”¨è»½é‡ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    hyperparameters={\n",
    "        'enable-grid-search': 'true',  # ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒæœ‰åŠ¹\n",
    "        'n-jobs': -1  # ä¸¦åˆ—å‡¦ç†\n",
    "    },\n",
    "    base_job_name='lecture-training-jobs',\n",
    "    max_run=1800  # æœ€å¤§30åˆ†\n",
    ")\n",
    "\n",
    "print(\"âœ… Estimatorè¨­å®šå®Œäº†\")\n",
    "print(f\"  ğŸ’» ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—: ml.m5.large\")\n",
    "print(f\"  ğŸ”¢ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°: 1\")\n",
    "print(f\"  ğŸ“„ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ: scripts/train_lecture.py\")\n",
    "print(f\"  âš™ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒæœ‰åŠ¹\")\n",
    "print(f\"  â±ï¸ æœ€å¤§å®Ÿè¡Œæ™‚é–“: 30åˆ†\")\n",
    "\n",
    "# ã‚³ã‚¹ãƒˆæƒ…å ±\n",
    "hourly_cost = 0.115  # ml.m5.large ã®æ™‚é–“å˜ä¾¡ï¼ˆUSDï¼‰\n",
    "estimated_time_hours = 10 / 60  # äºˆæƒ³å®Ÿè¡Œæ™‚é–“ï¼ˆ10åˆ†ï¼‰\n",
    "estimated_cost = hourly_cost * estimated_time_hours\n",
    "\n",
    "print(f\"\\nğŸ’° ã‚³ã‚¹ãƒˆæƒ…å ±:\")\n",
    "print(f\"  ğŸ’µ æ™‚é–“å˜ä¾¡: ${hourly_cost}/æ™‚é–“\")\n",
    "print(f\"  â±ï¸ äºˆæƒ³å®Ÿè¡Œæ™‚é–“: ç´„10åˆ†\")\n",
    "print(f\"  ğŸ’¸ äºˆæƒ³ã‚³ã‚¹ãƒˆ: ${estimated_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Jobsã®å®Ÿè¡Œ\n",
    "\n",
    "### ğŸ“š å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ\n",
    "- S3ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸTraining Jobsã®èµ·å‹•\n",
    "- å®Ÿè¡Œæ™‚é–“ã®æ¸¬å®š\n",
    "- ã‚¸ãƒ§ãƒ–ã®ç›£è¦–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ Training Jobså®Ÿè¡Œé–‹å§‹...\")\n",
    "print(f\"â±ï¸ äºˆæƒ³å®Ÿè¡Œæ™‚é–“: 8-12åˆ†\")\n",
    "print(f\"ğŸ“Š ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿: S3ã«ä¿å­˜ã•ã‚ŒãŸè¬›ç¾©ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\")\n",
    "\n",
    "training_jobs_start = time.time()\n",
    "\n",
    "# S3ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦Training Jobsã‚’å®Ÿè¡Œ\n",
    "lecture_estimator.fit({\n",
    "    'train': s3_paths['train'],\n",
    "    'validation': s3_paths['validation'],\n",
    "    'test': s3_paths['test']\n",
    "})\n",
    "\n",
    "training_jobs_total_time = time.time() - training_jobs_start\n",
    "\n",
    "print(f\"\\nğŸ‰ Training Jobså®Œäº†!\")\n",
    "print(f\"â±ï¸ å®Ÿéš›ã®å®Ÿè¡Œæ™‚é–“: {training_jobs_total_time:.1f}ç§’ ({training_jobs_total_time/60:.1f}åˆ†)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Jobsçµæœã®è©³ç´°åˆ†æ\n",
    "\n",
    "### ğŸ“š å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ\n",
    "- ã‚¸ãƒ§ãƒ–ã®å®Ÿè¡Œçµ±è¨ˆå–å¾—\n",
    "- ã‚³ã‚¹ãƒˆè¨ˆç®—\n",
    "- ãƒ­ã‚°ã¨ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Jobsã®è©³ç´°æƒ…å ±å–å¾—\n",
    "training_job_name = lecture_estimator.latest_training_job.job_name\n",
    "print(f\"ğŸ“‹ Training Jobè©³ç´°æƒ…å ±:\")\n",
    "print(f\"  ğŸ·ï¸ ã‚¸ãƒ§ãƒ–å: {training_job_name}\")\n",
    "\n",
    "# ã‚¸ãƒ§ãƒ–ã®å®Ÿè¡Œçµ±è¨ˆ\n",
    "training_job_description = sagemaker_session.describe_training_job(training_job_name)\n",
    "\n",
    "print(f\"\\nğŸ“Š å®Ÿè¡Œçµ±è¨ˆ:\")\n",
    "print(f\"  âœ… ã‚¸ãƒ§ãƒ–çŠ¶æ…‹: {training_job_description['TrainingJobStatus']}\")\n",
    "print(f\"  ğŸ’» ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—: {training_job_description['ResourceConfig']['InstanceType']}\")\n",
    "print(f\"  ğŸ”¢ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°: {training_job_description['ResourceConfig']['InstanceCount']}\")\n",
    "\n",
    "# å®Ÿè¡Œæ™‚é–“ã®è©³ç´°\n",
    "if 'TrainingStartTime' in training_job_description and 'TrainingEndTime' in training_job_description:\n",
    "    start_time = training_job_description['TrainingStartTime']\n",
    "    end_time = training_job_description['TrainingEndTime']\n",
    "    actual_training_time = (end_time - start_time).total_seconds()\n",
    "    print(f\"  â±ï¸ å®Ÿéš›ã®è¨“ç·´æ™‚é–“: {actual_training_time:.1f}ç§’ ({actual_training_time/60:.1f}åˆ†)\")\n",
    "\n",
    "# èª²é‡‘æ™‚é–“ã¨ã‚³ã‚¹ãƒˆ\n",
    "billable_seconds = training_job_description.get('BillableTimeInSeconds', 0)\n",
    "actual_cost = (billable_seconds / 3600) * hourly_cost\n",
    "\n",
    "print(f\"\\nğŸ’° ã‚³ã‚¹ãƒˆè©³ç´°:\")\n",
    "print(f\"  â±ï¸ èª²é‡‘æ™‚é–“: {billable_seconds}ç§’ ({billable_seconds/60:.1f}åˆ†)\")\n",
    "print(f\"  ğŸ’µ å®Ÿéš›ã®ã‚³ã‚¹ãƒˆ: ${actual_cost:.4f}\")\n",
    "print(f\"  ğŸ“Š äºˆæƒ³ã¨ã®å·®: ${abs(actual_cost - estimated_cost):.4f}\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ãƒ­ã‚°\n",
    "model_artifacts = lecture_estimator.model_data\n",
    "print(f\"\\nğŸ“¦ å‡ºåŠ›æƒ…å ±:\")\n",
    "print(f\"  ğŸ“„ ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ: {model_artifacts}\")\n",
    "print(f\"  ğŸ“Š CloudWatchãƒ­ã‚°: /aws/sagemaker/TrainingJobs/{training_job_name}\")\n",
    "\n",
    "# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒç”¨ã®æƒ…å ±ã‚’ä¿å­˜\n",
    "training_jobs_info = {\n",
    "    'job_name': training_job_name,\n",
    "    'total_time': training_jobs_total_time,\n",
    "    'training_time': actual_training_time if 'actual_training_time' in locals() else training_jobs_total_time,\n",
    "    'billable_seconds': billable_seconds,\n",
    "    'actual_cost': actual_cost,\n",
    "    'model_artifacts': model_artifacts\n",
    "}\n",
    "\n",
    "with open('training_jobs_info.json', 'w') as f:\n",
    "    json.dump(training_jobs_info, f, indent=2)\n",
    "    \n",
    "print(f\"\\nğŸ’¾ Training Jobsæƒ…å ±ã‚’ä¿å­˜: training_jobs_info.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
    "\n",
    "### ğŸ“š å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ\n",
    "- Training Jobsã§è¨“ç·´ã—ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤\n",
    "- ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ã®æ¨è«–ãƒ†ã‚¹ãƒˆ\n",
    "- ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ã‚³ã‚¹ãƒˆç®¡ç†\n",
    "- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”® æ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆé–‹å§‹...\")\n",
    "endpoint_start = time.time()\n",
    "\n",
    "# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½œæˆ\n",
    "print(\"  ğŸ“¡ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆä¸­...\")\n",
    "lecture_predictor = lecture_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium',  # æ¨è«–ç”¨è»½é‡ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n",
    "    endpoint_name=f'lecture-endpoint-{int(time.time())}'\n",
    ")\n",
    "\n",
    "endpoint_creation_time = time.time() - endpoint_start\n",
    "print(f\"  âœ… ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½œæˆå®Œäº†: {endpoint_creation_time:.1f}ç§’\")\n",
    "print(f\"  ğŸ·ï¸ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå: {lecture_predictor.endpoint_name}\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¨è«–ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
    "print(f\"\\nğŸ¯ æ¨è«–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...\")\n",
    "\n",
    "# S3ã‹ã‚‰ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆå°‘é‡ï¼‰\n",
    "test_data_sample = pd.read_csv(s3_paths['test']).head(5)\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆè¨“ç·´æ™‚ã¨åŒã˜å½¢å¼ã«å¤‰æ›ï¼‰\n",
    "print(f\"  ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {test_data_sample.shape}\")\n",
    "print(f\"  ğŸ“‹ ã‚«ãƒ©ãƒ æ•°: {len(test_data_sample.columns)}\")\n",
    "\n",
    "# targetã‚«ãƒ©ãƒ ã‚’é™¤å¤–ã—ã¦numpyé…åˆ—ã«å¤‰æ›\n",
    "if 'target' in test_data_sample.columns:\n",
    "    test_samples = test_data_sample.drop('target', axis=1).values\n",
    "    actual_labels = test_data_sample['target'].values\n",
    "else:\n",
    "    test_samples = test_data_sample.values\n",
    "    actual_labels = None\n",
    "    print(\"  âš ï¸ targetã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "print(f\"  ğŸ¯ æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {test_samples.shape}\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèªãƒ»ä¿®æ­£\n",
    "test_samples = test_samples.astype(np.float32)\n",
    "print(f\"  ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‹: {test_samples.dtype}\")\n",
    "\n",
    "try:\n",
    "    inference_start = time.time()\n",
    "    \n",
    "    # æ¨è«–å®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰\n",
    "    print(\"  ğŸ”® æ¨è«–ã‚’å®Ÿè¡Œä¸­...\")\n",
    "    predictions = lecture_predictor.predict(test_samples)\n",
    "    \n",
    "    inference_time = time.time() - inference_start\n",
    "    \n",
    "    print(f\"  âœ… æ¨è«–æˆåŠŸ!\")\n",
    "    print(f\"  â±ï¸ æ¨è«–æ™‚é–“: {inference_time:.4f}ç§’ (5ã‚µãƒ³ãƒ—ãƒ«)\")\n",
    "    print(f\"  ğŸš€ å¹³å‡æ¨è«–æ™‚é–“: {inference_time/5:.4f}ç§’/ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "    \n",
    "    # çµæœã®è¡¨ç¤º\n",
    "    if actual_labels is not None:\n",
    "        print(f\"\\nğŸ“Š æ¨è«–çµæœ:\")\n",
    "        correct_predictions = 0\n",
    "        for i, (pred, actual) in enumerate(zip(predictions, actual_labels)):\n",
    "            status = \"âœ…\" if pred == actual else \"âŒ\"\n",
    "            if pred == actual:\n",
    "                correct_predictions += 1\n",
    "            print(f\"  ã‚µãƒ³ãƒ—ãƒ« {i+1}: äºˆæ¸¬={pred}, å®Ÿéš›={actual} {status}\")\n",
    "        \n",
    "        accuracy = correct_predictions / len(predictions)\n",
    "        print(f\"\\nğŸ¯ æ¨è«–ç²¾åº¦ï¼ˆ5ã‚µãƒ³ãƒ—ãƒ«ï¼‰: {accuracy:.2f} ({correct_predictions}/{len(predictions)})\")\n",
    "    else:\n",
    "        print(f\"\\nğŸ“Š æ¨è«–çµæœ: {predictions}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æ¨è«–ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\")\n",
    "    print(\"\\nğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:\")\n",
    "    print(\"1. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£å¸¸ã«èµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª\")\n",
    "    print(\"2. ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒè¨“ç·´æ™‚ã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ç¢ºèª\")\n",
    "    print(\"3. CloudWatchãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n",
    "    print(f\"   ãƒ­ã‚°URL: https://console.aws.amazon.com/cloudwatch/home?region={region}#logEventViewer:group=/aws/sagemaker/Endpoints/{lecture_predictor.endpoint_name}\")\n",
    "    \n",
    "    # ã‚¨ãƒ©ãƒ¼ã§ã‚‚å‡¦ç†ã‚’ç¶™ç¶š\n",
    "    print(\"\\nâš ï¸ æ¨è«–ãƒ†ã‚¹ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œã—ã¾ã™\")\n",
    "    inference_time = 0\n",
    "    accuracy = 0\n",
    "\n",
    "# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ã‚³ã‚¹ãƒˆæƒ…å ±\n",
    "endpoint_hourly_cost = 0.056  # ml.t2.medium ã®æ™‚é–“å˜ä¾¡\n",
    "print(f\"\\nğŸ’° ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚³ã‚¹ãƒˆæƒ…å ±:\")\n",
    "print(f\"  ğŸ’» ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹: ml.t2.medium\")\n",
    "print(f\"  ğŸ’µ æ™‚é–“å˜ä¾¡: ${endpoint_hourly_cost}/æ™‚é–“\")\n",
    "print(f\"  ğŸ“… æœˆé¡æ¦‚ç®—: ${endpoint_hourly_cost * 24 * 30:.2f} (24æ™‚é–“ç¨¼åƒã®å ´åˆ)\")\n",
    "print(f\"  âš ï¸ é‡è¦: ä½¿ç”¨å¾Œã¯å¿…ãšã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å‰Šé™¤ï¼ˆé‡è¦ï¼ï¼‰\n",
    "print(\"ğŸ—‘ï¸ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ä¸­...\")\n",
    "try:\n",
    "    lecture_predictor.delete_endpoint()\n",
    "    print(\"âœ… ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤å®Œäº†\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "    print(\"ğŸ’¡ æ‰‹å‹•ã§AWSã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‹ã‚‰å‰Šé™¤ã—ã¦ãã ã•ã„\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Training Jobså­¦ç¿’å®Œäº†!\")\n",
    "print(f\"ğŸ“Š å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼:\")\n",
    "print(f\"  â±ï¸ Training Jobså®Ÿè¡Œæ™‚é–“: {training_jobs_total_time:.1f}ç§’\")\n",
    "print(f\"  ğŸ’° Training Jobsã‚³ã‚¹ãƒˆ: ${actual_cost:.4f}\")\n",
    "print(f\"  ğŸ”® æ¨è«–ãƒ†ã‚¹ãƒˆ: {'æˆåŠŸ' if 'accuracy' in locals() and accuracy > 0 else 'ã‚¹ã‚­ãƒƒãƒ—'}\")\n",
    "print(f\"  ğŸ—‘ï¸ ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: å®Œäº†\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Training Jobsã®ç‰¹å¾´ã‚’ä½“é¨“ã—ã¾ã—ãŸ:\")\n",
    "features = [\n",
    "    \"S3ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸè‡ªå‹•çš„ãªãƒ‡ãƒ¼ã‚¿å–å¾—\",\n",
    "    \"ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã®è¨“ç·´\",\n",
    "    \"è‡ªå‹•çš„ãªãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜\",\n",
    "    \"æ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¸ã®ç°¡å˜ãƒ‡ãƒ—ãƒ­ã‚¤\",\n",
    "    \"è©³ç´°ãªå®Ÿè¡Œçµ±è¨ˆã¨ã‚³ã‚¹ãƒˆç®¡ç†\",\n",
    "    \"ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\"\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    print(f\"  {i}. âœ… {feature}\")\n",
    "\n",
    "print(f\"\\nğŸš€ æ¬¡ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯: 04_comparison_and_summary.ipynb\")\n",
    "print(f\"   Script Modeã¨Training Jobsã®è©³ç´°æ¯”è¼ƒã‚’è¡Œã„ã¾ã™ï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
