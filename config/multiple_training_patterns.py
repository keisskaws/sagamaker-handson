#!/usr/bin/env python3
"""
SageMaker Training Jobs è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ä»¥ä¸‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆã§ãã¾ã™ï¼š
1. ç•°ãªã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã§ã®æ€§èƒ½æ¯”è¼ƒ
2. ç•°ãªã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ¯”è¼ƒ
3. ç•°ãªã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã®æ¯”è¼ƒ
4. ä¸¦åˆ—å®Ÿè¡Œã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
"""

import sagemaker
import boto3
import time
import json
import pandas as pd
from datetime import datetime
from sagemaker.sklearn.estimator import SKLearn
from sagemaker import get_execution_role
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultipleTrainingPatterns:
    def __init__(self):
        self.sagemaker_session = sagemaker.Session()
        self.role = get_execution_role()
        self.region = boto3.Session().region_name
        self.bucket = self.sagemaker_session.default_bucket()
        
        # S3ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‚’èª­ã¿è¾¼ã¿
        try:
            with open('s3_data_paths.json', 'r') as f:
                self.s3_paths = json.load(f)
            logger.info("S3ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æƒ…å ±ã‚’èª­ã¿è¾¼ã¿å®Œäº†")
        except FileNotFoundError:
            logger.error("S3ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            raise
    
    def create_estimator(self, config):
        """è¨­å®šã«åŸºã¥ã„ã¦Estimatorã‚’ä½œæˆ"""
        return SKLearn(
            entry_point=config['entry_point'],
            framework_version='1.0-1',
            py_version='py3',
            instance_type=config['instance_type'],
            instance_count=config.get('instance_count', 1),
            role=self.role,
            hyperparameters=config['hyperparameters'],
            base_job_name=config['job_name_prefix'],
            max_run=config.get('max_run', 3600)
        )
    
    def run_single_training(self, config):
        """å˜ä¸€ã®Training Jobã‚’å®Ÿè¡Œ"""
        logger.info(f"Training Jobé–‹å§‹: {config['name']}")
        start_time = time.time()
        
        try:
            estimator = self.create_estimator(config)
            
            # Training Jobå®Ÿè¡Œ
            estimator.fit(self.s3_paths)
            
            # çµæœã®å–å¾—
            job_name = estimator.latest_training_job.job_name
            job_description = self.sagemaker_session.describe_training_job(job_name)
            
            # å®Ÿè¡Œæ™‚é–“ã¨ã‚³ã‚¹ãƒˆã®è¨ˆç®—
            total_time = time.time() - start_time
            billable_seconds = job_description.get('BillableTimeInSeconds', 0)
            
            # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆ¥ã®æ™‚é–“å˜ä¾¡ï¼ˆUSD/æ™‚é–“ï¼‰
            instance_costs = {
                'ml.m5.large': 0.115,
                'ml.m5.xlarge': 0.230,
                'ml.m5.2xlarge': 0.460,
                'ml.c5.large': 0.108,
                'ml.c5.xlarge': 0.216
            }
            
            hourly_cost = instance_costs.get(config['instance_type'], 0.115)
            actual_cost = (billable_seconds / 3600) * hourly_cost
            
            result = {
                'name': config['name'],
                'job_name': job_name,
                'instance_type': config['instance_type'],
                'hyperparameters': config['hyperparameters'],
                'total_time': total_time,
                'training_time': billable_seconds,
                'cost': actual_cost,
                'status': job_description['TrainingJobStatus'],
                'model_artifacts': estimator.model_data
            }
            
            logger.info(f"Training Jobå®Œäº†: {config['name']} ({total_time:.1f}ç§’, ${actual_cost:.4f})")
            return result
            
        except Exception as e:
            logger.error(f"Training Jobå¤±æ•—: {config['name']} - {str(e)}")
            return {
                'name': config['name'],
                'status': 'Failed',
                'error': str(e),
                'total_time': time.time() - start_time
            }
    
    def run_parallel_training(self, configs, max_workers=3):
        """è¤‡æ•°ã®Training Jobã‚’ä¸¦åˆ—å®Ÿè¡Œ"""
        logger.info(f"{len(configs)}å€‹ã®Training Jobã‚’ä¸¦åˆ—å®Ÿè¡Œé–‹å§‹ (æœ€å¤§{max_workers}ä¸¦åˆ—)")
        
        results = []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # å…¨ã¦ã®ã‚¸ãƒ§ãƒ–ã‚’æŠ•å…¥
            future_to_config = {
                executor.submit(self.run_single_training, config): config 
                for config in configs
            }
            
            # å®Œäº†ã—ãŸã‚‚ã®ã‹ã‚‰çµæœã‚’åé›†
            for future in as_completed(future_to_config):
                config = future_to_config[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    logger.error(f"ä¸¦åˆ—å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {config['name']} - {str(e)}")
                    results.append({
                        'name': config['name'],
                        'status': 'Failed',
                        'error': str(e)
                    })
        
        return results
    
    def analyze_results(self, results):
        """çµæœã®åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        logger.info("çµæœåˆ†æä¸­...")
        
        # æˆåŠŸã—ãŸã‚¸ãƒ§ãƒ–ã®ã¿ã‚’åˆ†æ
        successful_results = [r for r in results if r.get('status') == 'Completed']
        
        if not successful_results:
            logger.warning("æˆåŠŸã—ãŸTraining JobãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # çµæœã‚’DataFrameã«å¤‰æ›
        df = pd.DataFrame(successful_results)
        
        print("\n" + "="*80)
        print("ğŸ¯ Training Jobs è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè¡Œçµæœ")
        print("="*80)
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"\nğŸ“Š å®Ÿè¡Œçµ±è¨ˆ:")
        print(f"  ç·å®Ÿè¡Œæ•°: {len(results)}")
        print(f"  æˆåŠŸæ•°: {len(successful_results)}")
        print(f"  å¤±æ•—æ•°: {len(results) - len(successful_results)}")
        
        if len(successful_results) > 0:
            print(f"\nâ±ï¸ å®Ÿè¡Œæ™‚é–“çµ±è¨ˆ:")
            print(f"  å¹³å‡å®Ÿè¡Œæ™‚é–“: {df['total_time'].mean():.1f}ç§’")
            print(f"  æœ€çŸ­å®Ÿè¡Œæ™‚é–“: {df['total_time'].min():.1f}ç§’")
            print(f"  æœ€é•·å®Ÿè¡Œæ™‚é–“: {df['total_time'].max():.1f}ç§’")
            
            print(f"\nğŸ’° ã‚³ã‚¹ãƒˆçµ±è¨ˆ:")
            print(f"  ç·ã‚³ã‚¹ãƒˆ: ${df['cost'].sum():.4f}")
            print(f"  å¹³å‡ã‚³ã‚¹ãƒˆ: ${df['cost'].mean():.4f}")
            print(f"  æœ€å°ã‚³ã‚¹ãƒˆ: ${df['cost'].min():.4f}")
            print(f"  æœ€å¤§ã‚³ã‚¹ãƒˆ: ${df['cost'].max():.4f}")
            
            # è©³ç´°çµæœãƒ†ãƒ¼ãƒ–ãƒ«
            print(f"\nğŸ“‹ è©³ç´°çµæœ:")
            display_df = df[['name', 'instance_type', 'total_time', 'cost']].copy()
            display_df['total_time'] = display_df['total_time'].round(1)
            display_df['cost'] = display_df['cost'].round(4)
            print(display_df.to_string(index=False))
            
            # æœ€é©ãªè¨­å®šã®æ¨å¥¨
            best_time = df.loc[df['total_time'].idxmin()]
            best_cost = df.loc[df['cost'].idxmin()]
            
            print(f"\nğŸ† æ¨å¥¨è¨­å®š:")
            print(f"  æœ€é€Ÿå®Ÿè¡Œ: {best_time['name']} ({best_time['total_time']:.1f}ç§’)")
            print(f"  æœ€å®‰å®Ÿè¡Œ: {best_cost['name']} (${best_cost['cost']:.4f})")
        
        # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = f'training_patterns_results_{timestamp}.json'
        
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {results_file}")
        
        return results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    trainer = MultipleTrainingPatterns()
    
    print("ğŸš€ SageMaker Training Jobs è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ")
    print("="*60)
    
    # ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®é¸æŠ
    print("\nå®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—æ¯”è¼ƒ")
    print("2. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒ") 
    print("3. ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¯”è¼ƒ")
    print("4. ã‚«ã‚¹ã‚¿ãƒ è¨­å®š")
    
    choice = input("\né¸æŠ (1-4): ").strip()
    
    if choice == '1':
        configs = get_instance_comparison_configs()
    elif choice == '2':
        configs = get_hyperparameter_comparison_configs()
    elif choice == '3':
        configs = get_algorithm_comparison_configs()
    elif choice == '4':
        configs = get_custom_configs()
    else:
        print("ç„¡åŠ¹ãªé¸æŠã§ã™")
        return
    
    print(f"\n{len(configs)}å€‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™...")
    
    # ä¸¦åˆ—å®Ÿè¡Œã®ç¢ºèª
    parallel = input("ä¸¦åˆ—å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower() == 'y'
    
    if parallel:
        max_workers = min(3, len(configs))  # æœ€å¤§3ä¸¦åˆ—
        results = trainer.run_parallel_training(configs, max_workers)
    else:
        results = []
        for config in configs:
            result = trainer.run_single_training(config)
            results.append(result)
    
    # çµæœåˆ†æ
    trainer.analyze_results(results)

if __name__ == '__main__':
    main()
